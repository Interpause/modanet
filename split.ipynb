{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from skmultilearn.model_selection import iterative_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos = json.load(open('./dataset/modanet_instances_all.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# would use a default dict but need to make sure all image ids are present\n",
    "data = {}\n",
    "for im in annos['images']:\n",
    "    data[im['id']] = np.zeros(len(annos['categories']))\n",
    "\n",
    "for a in annos['annotations']:\n",
    "    data[a['image_id']][a['category_id']-1] += 1\n",
    "\n",
    "X, y = zip(*data.items())\n",
    "y = np.stack(y)\n",
    "X = np.array(X).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only thing i could find online that attempts multi-label splits\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X,y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution train:  [16630. 11440. 11146. 61848. 20100. 11664.  6985. 18527. 28969.  5633.\n",
      " 10891.  4343.  4076.]\n",
      "distribution test:  [ 4246.  2917.  2813. 15311.  5108.  2928.  1812.  4646.  7321.  1442.\n",
      "  2764.  1105.  1040.]\n",
      "distribution similarity:  0.9999292789547258\n"
     ]
    }
   ],
   "source": [
    "print('distribution train: ', y_train.sum(axis=0))\n",
    "print('distribution test: ', y_test.sum(axis=0))\n",
    "a = y_train.sum(axis=0)/y_train.sum()\n",
    "b = y_test.sum(axis=0)/y_test.sum()\n",
    "# sorry I dont remember the chapter on hypothesis testing\n",
    "print('distribution similarity: ', np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1)\n",
    "X_test = X_test.reshape(-1)\n",
    "\n",
    "train_annos = {}\n",
    "train_annos['categories'] = annos['categories']\n",
    "train_annos['images'] = [im for im in annos['images'] if im['id'] in X_train]\n",
    "train_annos['annotations'] = [a for a in annos['annotations'] if a['image_id'] in X_train]\n",
    "\n",
    "test_annos = {}\n",
    "test_annos['categories'] = annos['categories']\n",
    "test_annos['images'] = [im for im in annos['images'] if im['id'] in X_test]\n",
    "test_annos['annotations'] = [a for a in annos['annotations'] if a['image_id'] in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/modanet_instances_train.json', 'w') as f:\n",
    "    json.dump(train_annos, f, separators=(',', ':'))\n",
    "\n",
    "with open('./dataset/modanet_instances_val.json', 'w') as f:\n",
    "    json.dump(test_annos, f, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a37a0150f95b6a1a14d1132343d4c81f896c5d583cd7e8189323bfabe3aeec2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('protection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
